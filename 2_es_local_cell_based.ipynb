{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Elastic search local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Links:\n",
    "-  url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ipynb(folder):\n",
    "    path = os.getcwd()+'\\\\'+folder\n",
    "    try:\n",
    "        dir_list = os.listdir(path)\n",
    "    except:\n",
    "        return \"this repository doesn't exist\"\n",
    "\n",
    "    file_id = 0\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ipynb\"):\n",
    "                file_id += 1\n",
    "    return file_id\n",
    "\n",
    "\n",
    "def code_output(cell,temp_dict):\n",
    "    \"\"\"\n",
    "    Explanation function\n",
    "    \"\"\"\n",
    "    if cell['outputs']==[]:\n",
    "        temp_dict['output_type'] = []\n",
    "        temp_dict['output'] = []\n",
    "    else:\n",
    "        if type(cell['outputs']) is list and len(cell['outputs'])>2:\n",
    "#             print(len(cell['outputs']),temp_dict['location'],temp_dict['file_cell'],cell['outputs'])\n",
    "            pass\n",
    "        output_type = cell['outputs'][0]['output_type']\n",
    "        temp_dict['output_type'] = output_type\n",
    "        if output_type == 'stream':\n",
    "            temp_dict['output'] = cell['outputs'][0]['text']\n",
    "        elif output_type == 'error':\n",
    "            temp_dict['output'] = cell['outputs'][0]['traceback']\n",
    "        elif temp_dict['output_type'] == 'display_data':\n",
    "            temp_dict['output'] = 'displayed data'\n",
    "        elif temp_dict['output_type'] == 'pyout':\n",
    "#             temp_dict['output'] = cell['outputs'][0]['html']\n",
    "            temp_dict['output'] = 'unkown'\n",
    "        elif 'data' in cell['outputs'][0].keys():\n",
    "            temp_dict['output'] = list(cell['outputs'][0]['data'].values())\n",
    "        elif 'text' in cell['outputs'][0].keys():\n",
    "            temp_dict['output'] = cell['outputs'][0]['text']\n",
    "        elif 'ename' in cell['outputs'][0].keys():\n",
    "            temp_dict['output'] = cell['outputs'][0]['ename']+cell['outputs'][0]['evalue']\n",
    "        else:\n",
    "            temp_dict['output'] = 'unknown'\n",
    "#             print(temp_dict['location'],temp_dict['file_cell'],cell)\n",
    "\n",
    "    return temp_dict\n",
    "\n",
    "\n",
    "def read_ipynb_cell(cell_id,cell_dict,file,folder,location,repo,user):\n",
    "    \"\"\"\n",
    "    Explanation function\n",
    "    \"\"\"\n",
    "    with open(location,encoding=\"utf8\") as notebook:\n",
    "        try: \n",
    "            data = json.load(notebook) #does the file have a correct json format\n",
    "        except Exception as e:\n",
    "            print(e,file)\n",
    "            return cell_id,cell_dict\n",
    "        \n",
    "        file_cell = 0\n",
    "        nbformat = data['nbformat']\n",
    "        if nbformat == 4: # current nbformat\n",
    "            data_cells =  data['cells']\n",
    "        elif nbformat == 3: # old nbformat\n",
    "            data_cells =  data['worksheets'][0]['cells']\n",
    "        elif nbformat == 2: # even older format\n",
    "            data_cells = data['worksheets'][0]['cells']\n",
    "\n",
    "        for cell in data_cells:\n",
    "            temp_dict = {}\n",
    "            if cell['cell_type'] == 'code' and (nbformat == 3 or nbformat == 2): #cell['source'] doesn't exist within this condition, use cell['input']\n",
    "                text = cell['input']\n",
    "            else:\n",
    "                text = cell['source']\n",
    "            clean_cell = list(map(lambda s: s.strip(), text)) #remove the '\\n' at the end of each string in the list         \n",
    "            single_string = ' '.join(clean_cell)\n",
    "            lines = len(clean_cell)\n",
    "\n",
    "            temp_dict['file_cell'] = file_cell\n",
    "            temp_dict['file'] = file\n",
    "            temp_dict['nbformat'] = data['nbformat']\n",
    "            temp_dict['folder'] = folder\n",
    "            temp_dict['user'] = user\n",
    "            temp_dict['repo'] =  repo\n",
    "            temp_dict['location'] = location\n",
    "            temp_dict['string'] = clean_cell\n",
    "#             temp_dict['char'] = single_string\n",
    "            temp_dict['lines'] = lines\n",
    "            temp_dict['cell_type'] = cell['cell_type']\n",
    "            if cell['cell_type'] == 'code':\n",
    "                temp_dict = code_output(cell,temp_dict)\n",
    "\n",
    "            cell_dict[cell_id] = temp_dict\n",
    "            cell_id += 1\n",
    "            file_cell += 1\n",
    "            \n",
    "    return cell_id,cell_dict\n",
    "\n",
    "\n",
    "def files_to_dict(file_dict):\n",
    "    \"\"\"\n",
    "    Explanation function\n",
    "    \"\"\"\n",
    "    cell_id = 0\n",
    "    cell_dict = {}\n",
    "\n",
    "    for file in file_dict.keys():\n",
    "        file_name = file_dict[file]['file']\n",
    "        user = file_dict[file]['user']\n",
    "        folder = file_dict[file]['folder']\n",
    "        location = file_dict[file]['location']\n",
    "        repo = file_dict[file]['repo']\n",
    "        #kan ik dit niet in één regel schrijven, ff controleren nog bijv a,b,c = dict.values()\n",
    "\n",
    "        cell_id_dict = read_ipynb_cell(cell_id,cell_dict,file_name,folder,location,repo,user)\n",
    "        cell_id = cell_id_dict[0]\n",
    "        cell_dict = cell_id_dict[1]\n",
    "    return cell_id,cell_dict\n",
    "\n",
    "\n",
    "def rec_to_actions(df):\n",
    "    for record in df.to_dict(orient=\"records\"):\n",
    "        yield ('{ \"index\" : { \"_index\" : \"%s\", \"_type\" : \"%s\" }}'% (INDEX, TYPE))\n",
    "        yield (json.dumps(record, default=int))\n",
    "      \n",
    "\n",
    "def index_marks(nrows, chunk_size):\n",
    "    return range(1 * chunk_size, (nrows // chunk_size + 1) * chunk_size, chunk_size)\n",
    "\n",
    "\n",
    "def split(dfm, chunk_size):\n",
    "    indices = index_marks(dfm.shape[0], chunk_size)\n",
    "    return np.split(dfm, indices)\n",
    "\n",
    "\n",
    "def decompose_folder_name(folder_name):\n",
    "    r1 = re.compile(\"([a-zA-Z0-9_-]+)\")\n",
    "    decompose = r1.findall(folder_name)\n",
    "    user,repo = decompose[0],decompose[1]\n",
    "    return user,repo\n",
    "\n",
    "def create_SE_from_folder(es,folder,file_id):\n",
    "    \"\"\"\n",
    "    Explenation\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    path = cwd+'\\\\'+folder\n",
    "    print(path)\n",
    "    file_dict = {}\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".ipynb\"):\n",
    "                location = os.path.join(root,file)\n",
    "#                 fn = root.split('\\\\')[6] # root verschilt per pc, documents\\\\test_thesis vs documents\\\\uni\\\\jaarx\\\\test_thesis\n",
    "                folder_name = root.split(folder)[1].split('\\\\')[1]\n",
    "                user,repo = decompose_folder_name(folder_name)\n",
    "                temp_dict = {}\n",
    "                temp_dict['file'] = file\n",
    "                temp_dict['folder'] = root.split('\\\\')[-1]\n",
    "                temp_dict['location'] = os.path.join(root,file)\n",
    "                temp_dict['user'] = user\n",
    "                temp_dict['repo'] = repo\n",
    "                \n",
    "                file_dict[file_id] = temp_dict\n",
    "                file_id += 1\n",
    "    \n",
    "    # CREATE DICT FOR ALL CELLS\n",
    "    cell_dict = files_to_dict(file_dict)[1]\n",
    " \n",
    "\n",
    "    # CREATE DATAFRAME FROM DICT\n",
    "    cell_df = pd.DataFrame.from_dict(cell_dict,orient='index')\n",
    "    cell_df.index = cell_df.index.set_names(['cell_id'])\n",
    "    cell_df = cell_df.fillna('empty').reset_index()\n",
    "    \n",
    "    # PUT DATAFRAME INTO ELASTIC SEARCH\n",
    "    for chuck in tqdm_notebook(split(cell_df, 1000)): # r = es.bulk(rec_to_actions(cell_df))\n",
    "        try:\n",
    "            r = es.bulk(rec_to_actions(chuck))\n",
    "        except Exception as e:\n",
    "            print('Bulk failed at df cell_id:',chuck.cell_id.iloc[0],'-',chuck.cell_id.iloc[-1])\n",
    "    return es,file_id,cell_df\n",
    "#     return cell_df,es,file_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create local elastic search variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHEATSHEET Elastic Search curl's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health status index      uuid                   pri rep docs.count docs.deleted store.size pri.store.size\n",
      "yellow open   repos_cell LftGIMs6S9CvBlBXWhjlOw   1   1     116397            0    303.1mb        303.1mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   212  100   212    0     0   3028      0 --:--:-- --:--:-- --:--:--  3072\n"
     ]
    }
   ],
   "source": [
    "# !curl \"http://localhost:9200/test\"\n",
    "# !curl -XDELETE \"localhost:9200/repos\"\n",
    "# !curl -XPOST \"http://localhost:9200/_shutdown\"\n",
    "\n",
    "!curl \"http://localhost:9200/_cat/indices?v\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count .ipynb files in current repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"this repository doesn't exist\", 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_ipynb('repos_sample'),count_ipynb('repos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put repositories into elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = 'http://localhost:9200/'\n",
    "es = Elasticsearch(hosts=[HOST]) \n",
    "\n",
    "\n",
    "INDEX = \"repos_sample\"\n",
    "TYPE = \"record\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "es = ''\n",
    "gallery_es,file_id,gallery_df = create_SE_from_folder(es,'repos',0)\n",
    "gallery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health status index      uuid                   pri rep docs.count docs.deleted store.size pri.store.size\n",
      "yellow open   repos_cell LftGIMs6S9CvBlBXWhjlOw   1   1     116397            0    303.1mb        303.1mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   212  100   212    0     0  17666      0 --:--:-- --:--:-- --:--:-- 17666\n"
     ]
    }
   ],
   "source": [
    "# check if dataframe succesfolly on Elastic Search\n",
    "!curl \"http://localhost:9200/_cat/indices?v\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
